{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on timescale\n",
    "\n",
    "The goal here is to try to setup reasonable scenarios on how we could use timescaledb + tiledb to manage sensor data.\n",
    "\n",
    "The notebook is divided in three parts:\n",
    "\n",
    " * boiler plate needed to setup the db infrastucture\n",
    " * a possible set of tables as a quick implementation\n",
    " * using the quick implentation on a set of use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boiler plate configuration\n",
    "\n",
    "The following are configuration details to setup timescaledb with the postgis extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres extensions loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as psy\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "from osgeo import ogr\n",
    "from osgeo import osr\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import tiledb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testdb\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "con = psy.connect(\"dbname=postgres host=timescaledb user=postgres password=foobar\")\n",
    "\n",
    "with con:\n",
    "    con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    with con.cursor() as cur:\n",
    "        cur.execute(\"DROP DATABASE IF EXISTS testdb;\")\n",
    "        cur.execute('CREATE DATABASE testdb')\n",
    "\n",
    "# not sure if the AUTOCOMMIT is needed\n",
    "with con:\n",
    "    con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    with con.cursor() as cur:   \n",
    "        cur.execute(\"CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE;\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1',)]\n",
      "(3819, 'EPSG', '+proj=longlat +ellps=bessel +towgs84=595.48,121.69,515.35,4.115,-2.9383,0.853,-3.408 +no_defs ')\n",
      "(3821, 'EPSG', '+proj=longlat +ellps=aust_SA +no_defs ')\n",
      "(3824, 'EPSG', '+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs ')\n",
      "[(3003, 'EPSG', '+proj=tmerc +lat_0=0 +lon_0=9 +k=0.9996 +x_0=1500000 +y_0=0 +ellps=intl +towgs84=-104.1,-49.1,-9.9,0.971,-2.917,0.714,-11.68 +units=m +no_defs ')]\n"
     ]
    }
   ],
   "source": [
    "con = psy.connect(\"dbname=testdb host=timescaledb user=postgres password=foobar\")\n",
    "\n",
    "with con:\n",
    "    with con.cursor() as cur:   \n",
    "        cur.execute(\"CREATE EXTENSION IF NOT EXISTS postgis;\")\n",
    "        cur.execute(\"SELECT postgis_version();\")\n",
    "        print(cur.fetchall())\n",
    "        cur.execute(\"SELECT srid, auth_name, proj4text FROM spatial_ref_sys LIMIT 3;\")\n",
    "        for x in cur.fetchall():\n",
    "            print(x)\n",
    "        cur.execute(\"SELECT srid, auth_name, proj4text FROM spatial_ref_sys WHERE srid = 3003\")\n",
    "        print(cur.fetchall())\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic reference system\n",
    "\n",
    "We would like to be able to easily express concepts as \"all objects within a <distance> radius from point p\" with the point p defined by its (longitude, latitude) pair in the [World Geodetic System (GPS, EPSG4326)](https://en.wikipedia.org/wiki/World_Geodetic_System). However, this does not imply that we need to store internally geographyical information using that coordinate system. The natual choice, since we are focusing on a region centered around the island of Sardinia is to have a local reference system, here EPSG3003 [see](http://www.sardegnageoportale.it/documenti/40_583_20150625090153.pdf), where the Earth sphere is, practically, mapped to a local plane and objects positions are expressed in distance in meters, in the North and East direction from a reference point.\n",
    "\n",
    "In the latter coordinate system, distances between objects can be directly computed using Pythagora's theorem.\n",
    "On the other hand, it is still useful to express object positions using their GPS coordinates. Therefore, we need to be able to handle conversions from one coordinate system to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import psycopg2.sql as sql\n",
    "from osgeo import ogr\n",
    "from osgeo import osr\n",
    "import json\n",
    "\n",
    "source = osr.SpatialReference()\n",
    "source.ImportFromEPSG(4326)\n",
    "\n",
    "target = osr.SpatialReference()\n",
    "target.ImportFromEPSG(3003)\n",
    "\n",
    "transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "def map_to_monte_mario(wkt):\n",
    "    geom = ogr.CreateGeometryFromWkt(wkt)\n",
    "    geom.Transform(transform)\n",
    "    return geom.ExportToWkt()\n",
    "\n",
    "\n",
    "def take_by_n(a, n):\n",
    "    c = it.cycle(range(2*n))\n",
    "    for k, g in it.groupby(a, lambda _: next(c) < n):\n",
    "        yield [_ for _ in g]\n",
    "\n",
    "\n",
    "def format_to_sql_tuple(t):\n",
    "    \"Convert tuple t to an SQL.Composable.\"\n",
    "    return  sql.SQL(\"({})\").format(sql.SQL(', ').join(sql.Literal(v) for v in t))\n",
    "\n",
    "\n",
    "def execute_in_context(conn, SQL):\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(SQL)\n",
    "\n",
    "    \n",
    "def load_data_by_chunks(conn, data, chunk_size, into, format_to_sql_tuple):\n",
    "    values = take_by_n(data, chunk_size)\n",
    "    for v in values:\n",
    "        s = sql.SQL(into) + sql.SQL(' VALUES ')\n",
    "        s += sql.SQL(', ').join(format_to_sql_tuple(_) for _ in v)\n",
    "        execute_in_context(conn, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A prototype implementation\n",
    "\n",
    "In this section we define a prototype implementation that is based on the following model:\n",
    "\n",
    " * a **sensor** is an identifiable device of a given **sensor_type** that generates a well defined datum at acquisition events, it has a geographical footprint and associated to it there is a set of metainformations (e.g., is the sensor broken?);\n",
    " * a **sensor_type** describes a class of sensors;\n",
    " * a **node** is a physical object that controls a group of sensors;\n",
    " * a **station** is a phyisical object that controls a group of nodes;\n",
    " * a **measure** represent the datum collected at the acquisition event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor type\n",
    "\n",
    "A sensor type is, externally, uniquely identified by its uuid tag. Internally, it is indexed and referred to by using its, db generated, id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sensor_types_table(conn):\n",
    "    \"\"\"The sensor types table mantains the definition of the sensor types.\n",
    "        <id(int)>,<stype uuid>,<json>\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "    CREATE TABLE  sensor_types (\n",
    "           id          SERIAL PRIMARY KEY,\n",
    "           tag         UUID UNIQUE,\n",
    "           description JSONB);\n",
    "    \"\"\"\n",
    "    execute_in_context(conn, SQL)    \n",
    "\n",
    "\n",
    "def destroy_sensor_types_table(conn):\n",
    "    \"\"\"\n",
    "    Can be safely called even when the sensor_types table does not exist.\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "    DROP TABLE IF EXISTS sensor_types;\n",
    "    \"\"\"\n",
    "    execute_in_context(conn, SQL)\n",
    "\n",
    "\n",
    "def get_sensor_types_mapping(conn):\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT id, tag from sensor_types;\")\n",
    "            uuid_to_id = {}\n",
    "            for r in cur.fetchall():\n",
    "                uuid_to_id[r[1]] = r[0]\n",
    "            return uuid_to_id\n",
    "\n",
    "\n",
    "def load_sensor_types(conn, data, validate=False, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Load an iterable of sensor types definitions.\n",
    "    Each element of data should be an iterable with 3 fields:\n",
    "    (<uuid of sensor_type>, <desc>)\n",
    "\n",
    "    e.g.,\n",
    "      data = [('2e174cf0-fbb2-4e2d-b1ab-230c87a3166c', {'key': 'value'}),]\n",
    "    \"\"\"\n",
    "    def fix_json(t):\n",
    "        t2 = (t[0], json.dumps(t[1]))\n",
    "        return format_to_sql_tuple(t2)\n",
    "    into = \"INSERT INTO sensor_types (tag, description)\"\n",
    "    load_data_by_chunks(conn, data, chunk_size, into, fix_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def simulate_sensor_types(n):\n",
    "    return [(str(uuid.uuid4()), {'key': 'value{}'.format(_)}) for _ in range(n)]        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = psy.connect(\"dbname=testdb host=timescaledb user=postgres password=foobar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_sensor_types_table(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sensor_types_table(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = simulate_sensor_types(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sensor_types(con, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sensor_types(conn, data):\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute('SELECT * from sensor_types;')\n",
    "            rdata = cur.fetchall()\n",
    "            return rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = check_sensor_types(con, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata = [(1 + _,) + d for _, d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 'cbca3889-2731-4d2c-b3e9-4b6f1c233bfe', {'key': 'value0'}),\n",
       " (1, 'cbca3889-2731-4d2c-b3e9-4b6f1c233bfe', {'key': 'value0'}))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdata[0], rdata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata[0] == vdata[0], rdata[50] == vdata[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "\n",
    "A node is, externally, uniquely identified by its uuid tag. Internally, it is indexed and referred to by using its, db generated, id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nodes_table(conn):\n",
    "    \"\"\"The nodes table mantains the definition of the nodes.\n",
    "        <id(int)>,<stype uuid>, <geo>, <json>\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "    CREATE TABLE  nodes (\n",
    "           id          SERIAL PRIMARY KEY,\n",
    "           tag         UUID UNIQUE,\n",
    "           station     INT4 NOT NULL,\n",
    "           geom        GEOMETRY,\n",
    "           description JSONB);\n",
    "    \"\"\"\n",
    "    execute_in_context(conn, SQL)    \n",
    "\n",
    "\n",
    "def destroy_nodes_table(conn):\n",
    "    \"\"\"\n",
    "    Can be safely called even when the sensor_types table does not exist.\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "    DROP TABLE IF EXISTS nodes;\n",
    "    \"\"\"\n",
    "    execute_in_context(conn, SQL)\n",
    "\n",
    "def get_nodes_mapping(conn):\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT id, tag from nodes;\")\n",
    "            nodes_uuid_to_id = {}\n",
    "            for r in cur.fetchall():\n",
    "                nodes_uuid_to_id[r[1]] = r[0]\n",
    "            return nodes_uuid_to_id\n",
    "\n",
    "def load_nodes(conn, data, validate=False, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Load an iterable of nodes definitions.\n",
    "    Each element of data should be an iterable with 3 fields:\n",
    "    (<uuid of node>, <station id>, <position>, <desc>)\n",
    "\n",
    "    e.g.,\n",
    "      data = [('2e174cf0-fbb2-4e2d-b1ab-230c87a3166c', 1, 'POINT(9.220304 39.276140)', {'key': 'value'}),]\n",
    "    \"\"\"\n",
    "    def fix_geom_and_json(t):    \n",
    "        return  sql.SQL(\"({})\").format(sql.SQL(', ').join([\n",
    "            sql.Literal(t[0]), sql.Literal(t[1]),\n",
    "            sql.SQL(\"ST_GeomFromText('%s', 3003)\" % map_to_monte_mario(t[2])),\n",
    "            sql.Literal(json.dumps(t[3]))]))\n",
    "    into = \"INSERT INTO nodes (tag, station, geom, description)\"\n",
    "    load_data_by_chunks(conn, data, chunk_size, into, fix_geom_and_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_nodes_table(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nodes_table(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensors\n",
    "\n",
    "A sensor is connected to a node and the nodes to a station. The geometrical footprint is expressed using the following [OpenGIS WKT](https://postgis.net/docs/using_postgis_dbmanagement.html) notation:\n",
    "```\n",
    "'POINT(9.220304 39.276140)' # a single point\n",
    "'LINESTRING(0 0, 1 1, 1 2)' # a polyline\n",
    "'POLYGON((0 0, 4 0, 4 4, 0 4, 0 0), (1 1, 2 1, 2 2, 1 2,1 1))' # a polygon with a hole.\n",
    "'MULTIPOINT((0 0), (1 2))' # \n",
    "```\n",
    "\n",
    "All the coordinates should be in EPSG(4326). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sensors_table(conn):\n",
    "    \"\"\"\n",
    "    The sensors table mantains information on specific sensors\n",
    "\n",
    "    <sid(int)>,<stypeid>,<stationid>,<geom>,<JSONB>\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    SQL = \"\"\"\n",
    "    CREATE TABLE sensors (\n",
    "           id          SERIAL PRIMARY KEY,\n",
    "           tag         UUID UNIQUE,\n",
    "           stype       INT4 NOT NULL,\n",
    "           node        INT4 NOT NULL,\n",
    "           geom        GEOMETRY,\n",
    "           description JSONB);\n",
    "    \"\"\"\n",
    "    execute_in_context(conn, SQL)    \n",
    "\n",
    "\n",
    "def destroy_sensors_table(conn):\n",
    "    \"\"\"\n",
    "    Can be safely called even when the sensors table does not exists.\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "    DROP TABLE IF EXISTS sensors;\n",
    "    \"\"\"\n",
    "    execute_in_context(conn, SQL)\n",
    "\n",
    "\n",
    "def get_sensors_mapping(conn):\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT id, tag from sensors;\")\n",
    "            uuid_to_id = {}\n",
    "            for r in cur.fetchall():\n",
    "                uuid_to_id[r[1]] = r[0]\n",
    "            return uuid_to_id\n",
    "\n",
    "\n",
    "def load_sensors(conn, data, validate=False, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Load an iterable of sensor definitions data to the sensors table.\n",
    "    Each element of data should be an iterable with 5 fields\n",
    "\n",
    "    <stypeid>,<stationid>,<geom>,<json>\n",
    "    \n",
    "    \"\"\"\n",
    "    # FIXME it appears that I cannot trigger psycopg2 JSON support\n",
    "    def fix_geom_and_json(t):    \n",
    "        return  sql.SQL(\"({})\").format(sql.SQL(', ').join([\n",
    "            sql.Literal(t[0]), sql.Literal(t[1]), sql.Literal(t[2]),\n",
    "            sql.SQL(\"ST_GeomFromText('%s', 3003)\" % map_to_monte_mario(t[3])),\n",
    "            sql.Literal(json.dumps(t[4]))]))\n",
    "    into = \"INSERT INTO sensors (tag, stype, node, geom, description)\"\n",
    "    load_data_by_chunks(conn, data, chunk_size, into, fix_geom_and_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_sensors(n):\n",
    "    return [(str(uuid.uuid4()), 1, 1, 'POINT(9.220304 39.276140)', {'key': 'value{}'.format(_)}) \n",
    "            for _ in range(n)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sensors(conn, data):\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute('SELECT id, tag, stype, node, ST_AsText(ST_Transform(geom,4326)), description from sensors;')\n",
    "            rdata = cur.fetchall()\n",
    "            return rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_sensors_table(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sensors_table(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = simulate_sensors(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sensors(con, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = check_sensors(con, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata = [(1 + _,) + d for _, d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a round-off problem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,\n",
       "  '7065fd86-eac4-4029-8782-bbbe943296f6',\n",
       "  1,\n",
       "  1,\n",
       "  'POINT(9.22030400716716 39.2761400015204)',\n",
       "  {'key': 'value0'}),\n",
       " (1,\n",
       "  '7065fd86-eac4-4029-8782-bbbe943296f6',\n",
       "  1,\n",
       "  1,\n",
       "  'POINT(9.220304 39.276140)',\n",
       "  {'key': 'value0'}),\n",
       " (51,\n",
       "  'abc72b02-a6a9-4541-8095-b8706c13393c',\n",
       "  1,\n",
       "  1,\n",
       "  'POINT(9.22030400716716 39.2761400015204)',\n",
       "  {'key': 'value50'}),\n",
       " (51,\n",
       "  'abc72b02-a6a9-4541-8095-b8706c13393c',\n",
       "  1,\n",
       "  1,\n",
       "  'POINT(9.220304 39.276140)',\n",
       "  {'key': 'value50'}))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata[0], vdata[0], rdata[50], vdata[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures table\n",
    "\n",
    "This is the critical part of the exercise.\n",
    "\n",
    "What we are trying to do is to use a *entity, attribute, value* like formalism to uniformly manage all possible measure events. Specifically,\n",
    "\n",
    " * a point sensor (say temperature) will generate a record where only the value part has a value assigned and NULL on the others;\n",
    " * a, say, radar, sensor will generate a record with NULL in the value field with an url that points to the tiledb array and indx that selects the relevant frame;\n",
    " * a value measured by a moving sensor will have the value field and the index field assigned and NULL on the url field.\n",
    " \n",
    "Of course, we use the type of the sensor\n",
    "\n",
    "**NOTE** we could, denormalize everything, but, for the time being, it is probably better to wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_measures_table(conn):\n",
    "    \"\"\"\n",
    "    The measures table mantains information on the acquired data.\n",
    "\n",
    "    <timestamp>,<sid>,<floatvalue>|NULL,<ref>|NULL,<indx>|NULL\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "    CREATE TABLE measures (\n",
    "           time   TIMESTAMPTZ NOT NULL,\n",
    "           sensor INT4        NOT NULL,\n",
    "           value  REAL,\n",
    "           url    TEXT,\n",
    "           indx   INT4);\n",
    "    SELECT create_hypertable('measures', 'time');\n",
    "    CREATE INDEX measures_sensor_index on measures(sensor);\n",
    "    \"\"\"\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(SQL)\n",
    "\n",
    "\n",
    "def destroy_measures_table(conn):\n",
    "    \"\"\"\n",
    "    Can be safely called even when the measures table does not exists.\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "    DROP TABLE IF EXISTS measures;\n",
    "    \"\"\"\n",
    "    execute_in_context(conn, SQL)\n",
    "\n",
    "\n",
    "def load_measures(conn, data, validate=False, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Load an iterable of measures data to the measures table.\n",
    "    Each element of data should be an iterable with 4 fields:\n",
    "    (<timestamp>,<sid>,<floatvalue>|NULL,<url>|NULL,<indx>|NULL)\n",
    "\n",
    "    Legal combinations are:\n",
    "\n",
    "      (<timestamp>, <sid>, <floatvalue>, None, None) # standard scalar\n",
    "      (<timestamp>, <sid>, None, <reftoarrayseq>, <arrayidx>) #array seq data\n",
    "      (<timestamp>, <sid>, None, None, <idx>) # trace data\n",
    "\n",
    "    \"\"\"\n",
    "    into = \"INSERT INTO measures (time, sensor, value, url, indx)\"\n",
    "    load_data_by_chunks(conn, data, chunk_size, into, format_to_sql_tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_measures(n):\n",
    "    now = datetime.now()\n",
    "    return [(now + timedelta(seconds=5*_), 1, 0.02 * _, None, None) for _ in range(n)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_measures(conn, data):\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute('SELECT * from measures;')\n",
    "            rdata = cur.fetchall()\n",
    "            return rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_measures_table(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_measures_table(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = simulate_measures(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_measures(con, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = check_measures(con, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((datetime.datetime(2019, 4, 23, 11, 16, 3, 379599, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)),\n",
       "  1,\n",
       "  0.0,\n",
       "  None,\n",
       "  None),\n",
       " (datetime.datetime(2019, 4, 23, 11, 16, 3, 379599), 1, 0.0, None, None),\n",
       " (datetime.datetime(2019, 4, 23, 11, 20, 13, 379599, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)),\n",
       "  1,\n",
       "  1.0,\n",
       "  None,\n",
       "  None),\n",
       " (datetime.datetime(2019, 4, 23, 11, 20, 13, 379599), 1, 1.0, None, None))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata[0], data[0], rdata[50], data[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cases and scenarios\n",
    "\n",
    "We will consider the following scenarios:\n",
    "\n",
    " 1. A network of traffic sensors distributed along major traffic routes\n",
    " 2. A meteo radar\n",
    " 3. A collection of energy/meteo sensors distributed across the city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A network of traffic sensors\n",
    "\n",
    "The data flux is coming from a single station that collects data coming from 1568 nodes, each of which refers to a specific oriented edge of the road network and, itself, collects data from 4 specialized traffic sensors (*jam*, *speed*, *flux*, *length*). The specific data collected from each sensor is FIXME. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Station\n",
    "\n",
    "FIXME, we currently do not have support for stations, so we assume that we have a single station with id 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node\n",
    "\n",
    "Each node is identified by its *uuid* and has, as minimal attributes, an *osm_edge* and a reference FIXME position intentified by a *lon* and a *lat*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "import itertools as it\n",
    "        \n",
    "nodes = []\n",
    "\n",
    "with io.open('./data/traffic/nodes.csv') as f:\n",
    "    df = csv.DictReader(f)\n",
    "    for r in df:\n",
    "        nodes.append((r['uuid'], 1, 'POINT({} {})'.format(r['lon'], r['lat']), {'osm_edge': r['osm_edge']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_nodes(con, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_uuid_to_id = get_nodes_mapping(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensor types\n",
    "\n",
    "We need to define 4 sensor types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_types = []\n",
    "\n",
    "with io.open('./data/traffic/sensor_types.csv') as f:\n",
    "    df = csv.DictReader(f)\n",
    "    for r in df:\n",
    "        sensor_types.append((r['uuid'], json.loads(r['description'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sensor_types(con, sensor_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_types_uuid_to_id = get_sensor_types_mapping(con)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensors definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = []\n",
    "with io.open('./data/traffic/sensors.csv') as f:\n",
    "    df = csv.DictReader(f)\n",
    "    for r in df:\n",
    "        sensors.append((r['uuid'], \n",
    "                        sensor_types_uuid_to_id[r['type']], \n",
    "                        nodes_uuid_to_id[r['node']],\n",
    "                        'POINT({} {})'.format(r['lon'], r['lat']), {'key': 'value'})\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sensors(con, sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_uuid_to_id = get_sensors_mapping(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual measures\n",
    "\n",
    "The measures file contains 84511921 rows. Each row\n",
    "has the following structure:\n",
    "\n",
    "```\n",
    "[zag@pflip traffic]$ head measures.csv \n",
    "uuid,time,measure\n",
    "98359c6d-863a-4c94-a997-d0e5446a489f,2019-02-21T11:32:08Z,2.76693\n",
    "77cb21dc-a2e3-4434-96f6-baa15748979d,2019-02-21T11:32:08Z,26.93\n",
    "156ec27f-0642-45a4-8bbb-c1b31649e6e5,2019-02-21T11:32:08Z,39.5\n",
    "2fad7fbe-5923-43d2-85cc-96a0dd782263,2019-02-21T11:32:08Z,4.6948\n",
    "b376da04-d521-4c0e-98dc-c683bf714281,2019-02-21T11:32:08Z,3.03756\n",
    "aa3e95cf-78f8-4a63-9e6e-61a794079ee0,2019-02-21T11:32:08Z,16.09\n",
    "12e7b744-794d-482b-ac84-cf5daeb039ec,2019-02-21T11:32:08Z,26.0\n",
    "5808faf1-1040-47d1-9cfb-6d0a7ebe458c,2019-02-21T11:32:08Z,0.01049\n",
    "9b00d24a-6798-4a60-bc2d-c118acebd6ae,2019-02-21T11:32:38Z,1.49068\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('./data/traffic/measures.csv') as f:\n",
    "    df = csv.DictReader(f)\n",
    "    measures = [(datetime.strptime(\n",
    "                     r['time'],'%Y-%m-%dT%H:%M:%SZ'),\n",
    "                 sensors_uuid_to_id[r['uuid']],\n",
    "                 r['measure'])\n",
    "                for r in df]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "with io.open('./data/traffic/measures.csv') as f:\n",
    "    df = csv.DictReader(f)\n",
    "    data = take_by_n(df, n=10000)\n",
    "    for chunk in data:\n",
    "        measures = [(datetime.strptime(r['time'],'%Y-%m-%dT%H:%M:%SZ'),\n",
    "                     sensors_uuid_to_id[r['uuid']],\n",
    "                     r['measure'], None, None)\n",
    "                    for r in chunk]\n",
    "        sys.stdout.write('.')\n",
    "        load_measures(con, measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
